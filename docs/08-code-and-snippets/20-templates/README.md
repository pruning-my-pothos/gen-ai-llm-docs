---
title: "Templates (Code & Snippets)"
archetype: "index"
status: "active"
owner: "NNLP"
maintainer: "NNLP"
version": "1.0.0"
tags: ["templates", "configuration", "project-skeleton", "automation", "index"]
last_reviewed: "2025-12-31"
---

# Templates (Code & Snippets)

This section provides a collection of ready-to-use templates and project skeletons designed to accelerate your LLM development. From configuration files for various components to full boilerplate projects, these templates aim to standardize common setups and tasks.

:::info[Goal: Accelerate Development and Standardize Workflows]
The objective is to provide developers with foundational structures and examples that can be quickly adapted, reducing setup time and promoting consistent practices across LLM projects.
:::

## Guides and Snippets

-   [**Config Examples (Directory)**](./config-examples/README.md): A collection of example configuration files for managing LLM APIs, RAG pipelines, LLM agents, and batch data processing tasks.

-   [**Python LLM Project Skeleton (Directory)**](./project-skeleton-python/README.md): A minimal, yet fully functional, Python project boilerplate for interacting with LLMs, especially local OpenAI-compatible servers.

-   [**Node.js LLM Project Skeleton (Directory)**](./project-skeleton-node/README.md): A minimal, yet fully functional, Node.js/TypeScript project boilerplate for interacting with LLMs, especially local OpenAI-compatible servers.

-   [**LLM Evaluation Report Template (`eval-report-template.md`)**](./eval-report-template.md): A structured template for documenting the results of your LLM or RAG evaluation runs, crucial for communicating performance and guiding improvements.

-   [**LLM Debug Runbook Template (`runbook-debug-template.md`)**](./runbook-debug-template.md): A step-by-step guide template for diagnosing and resolving common issues encountered in LLM applications, designed to minimize Mean Time To Resolution (MTTR).

:::tip[Copy, Adapt, Automate]
These templates are designed to be copied and adapted to your specific project needs. Use them to bootstrap new features, standardize configurations, and build robust automated workflows for your LLM applications.
:::