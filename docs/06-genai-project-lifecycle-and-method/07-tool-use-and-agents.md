---
title: "Tool Use and Agents"
archetype: "fundamentals"
status: "active"
owner: "Shailesh (Shaily)"
maintainer: "Shailesh (Shaily)"
version: "0.1.0"
tags: ["genai-llm", "structured-output", "tools", "schema", "apis", "agents", "orchestration"]
last_reviewed: "2025-12-28"
---

# Structured Output, Tool Use, and Agents

:::info[Value Proposition]
Move beyond natural language generation to enable LLMs to produce data in predictable formats (e.g., JSON, YAML, XML) and interact with external systems (APIs, databases). This is essential for integrating LLMs into automated workflows and building reliable AI-assisted applications.
:::

## Overview

While LLMs excel at generating free-form text, many tasks require structured outputs that can be parsed and acted upon by other software components. Furthermore, to perform complex, multi-step tasks, LLMs need the ability to use external tools. This document explores techniques for guiding LLMs to produce structured data and how to enable them to invoke and interpret external tool calls, transforming them from text generators into agents capable of interacting with the world.

**Goal**: Enable LLMs to produce machine-readable output and execute actions through external tools.
**Anti-pattern**: Expecting an LLM to reliably generate complex code or interact with APIs solely through free-form conversational prompts, leading to unreliable parsing and execution failures.

---

## Structured Output

### Techniques for Structured Output

1.  **Direct Instruction**: Explicitly ask the LLM for a specific format.
    > "Generate the response as a JSON object."

2.  **Schema Definition**: Provide the LLM with a formal schema (e.g., JSON Schema, TypeScript interfaces).
    > "Generate a TypeScript interface for a `User` object that conforms to the following JSON Schema: `{ ... }`"

3.  **Few-shot Examples**: Give the LLM examples of the desired structured output.
    > "Here is an example of a valid API response: `{'status': 'success', 'data': {...}}`. Generate a similar response for X."

4.  **Grammar/Format Constraints**: Use specific libraries (e.g., `lm-format-enforcer` in Python) or prompt techniques that force the LLM to adhere to a grammar.

### Example: Generating JSON Output

**Prompt**:
> "Generate a JSON object for a product. It should have `name` (string), `price` (number), `inStock` (boolean), and `tags` (array of strings)."

**LLM Output**:
```json
{
  "name": "Wireless Ergonomic Mouse",
  "price": 49.99,
  "inStock": true,
  "tags": ["peripherals", "ergonomic", "wireless"]
}
```

---

## Tool Use (Function Calling)

Tool use (also known as function calling) enables LLMs to interact with external systems by calling predefined functions. The LLM's role shifts from merely generating text to generating _arguments for functions_ that then perform real-world actions.

### How Tool Use Works

1.  **Define Tools**: You provide the LLM with a description of available functions, including their names, parameters, and what they do (often using schemas).
2.  **User Request**: The user makes a request that might require an external action.
3.  **LLM Determines Tool**: The LLM analyzes the request and decides if a tool is needed. If so, it generates the arguments to call that tool.
4.  **Execute Tool**: Your application code executes the tool with the LLM-generated arguments.
5.  **LLM Gets Tool Output**: The output of the tool is fed back to the LLM.
6.  **LLM Responds**: The LLM generates a final, informed response to the user.

### Example: Calling a Weather API

**Tool Definition (provided to LLM):**
```json
{
  "name": "getCurrentWeather",
  "description": "Get the current weather for a location",
  "parameters": {
    "type": "object",
    "properties": {
      "location": {
        "type": "string",
        "description": "The city and state, e.g. San Francisco, CA"
      },
      "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
    },
    "required": ["location"]
  }
}
```

**User Request**: "What's the weather like in Boston?"

**LLM Tool Call (generated by LLM):**
```json
{
  "tool_name": "getCurrentWeather",
  "parameters": {
    "location": "Boston, MA"
  }
}
```

---
## Agents and Orchestration

An AI agent is a system that uses an LLM to reason, plan, and execute a sequence of actions to achieve a goal. Agents are goal-directed loops that perceive their environment, plan steps, act using tools, and observe the results.

### When to Use Agents

- Multi-step tasks needing planning and tool use.
- Environments where intermediate verification is possible.

### Guardrails for Agents

- **Tool allowlist** with schemas and side-effect constraints.
- **Planning limits**: max steps, stop conditions, escalation paths.
- **Observation/verification** after each critical action.
- **Audit**: log plans, tool calls, and state transitions.

```mermaid
flowchart LR
    Request[User Request] --> Agent{Agent}
    Agent --> Plan[Plan Steps]
    Plan --> ToolCall[Tool Call]
    ToolCall --> External[External System]
    External --> Observation[Observation]
    Observation --> Agent
    Agent --> Response[Final Response]

    classDef step fill:#E6F7FF,stroke:#1B75BB,color:#0F1F2E;
    class Request,Agent,Plan,ToolCall,External,Observation,Response step;
```

---

## Common Pitfalls

| Pitfall                   | Impact                                   | Correction                                     |
| :------------------------ | :--------------------------------------- | :--------------------------------------------- |
| **Vague Schema Definitions** | LLM generates invalid or incomplete structured data. | Provide clear, explicit JSON Schemas or type definitions. |
| **Underspecified Tool Descriptions** | LLM calls tools with incorrect arguments or in wrong situations. | Make tool descriptions precise, including parameter types and examples. |
| **Ignoring Tool Output**  | LLM doesn't use tool results to inform its response, leading to errors. | Ensure tool output is correctly fed back to the LLM and prompt it to use that context. |
| **Unbounded Agent Loops** | Agent gets stuck in a loop, wasting resources. | Implement stop conditions, max steps, and human-in-the-loop checkpoints. |
| **Giving Agents Destructive Tools**| Agent causes unintended side effects. | Use read-only tools where possible and require human confirmation for write actions. |


---

## Last Reviewed / Last Updated

- Last reviewed: 2025-12-28
- Version: 0.1.0