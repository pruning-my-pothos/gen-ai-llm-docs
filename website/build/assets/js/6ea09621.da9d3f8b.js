"use strict";(self.webpackChunknnlp_website=self.webpackChunknnlp_website||[]).push([[7437],{18051(e){e.exports=JSON.parse('{"tag":{"label":"security","permalink":"/NNLP/docs/tags/security","allTagsPath":"/NNLP/docs/tags","count":4,"items":[{"id":"07-guardrails-and-governance/data-boundaries","title":"Data Boundaries","description":"To prevent data leaks, we classify data into three zones. These zones dictate which AI tools can be used and what context can be provided.","permalink":"/NNLP/docs/07-guardrails-and-governance/data-boundaries"},{"id":"05-professional-scenarios/02-refactoring-legacy-auth","title":"Scenario: Refactoring Legacy Auth","description":"Demonstrate how to safely refactor a critical, untyped legacy module into TypeScript without causing regressions or downtime.","permalink":"/NNLP/docs/05-professional-scenarios/02-refactoring-legacy-auth"},{"id":"09-templates/threat-model-lite-template","title":"Template: Threat Model Lite","description":"Fill this out for any feature that uses an LLM. If you answer \\"Yes\\" to any High Risk item, you must have a specific mitigation listed.","permalink":"/NNLP/docs/09-templates/threat-model-lite-template"},{"id":"07-guardrails-and-governance/threat-model-lite","title":"Threat Model Lite","description":"Traditional threat modeling takes days. \\"Threat Model Lite\\" takes 10 minutes. It focuses exclusively on the unique risks introduced by AI components.","permalink":"/NNLP/docs/07-guardrails-and-governance/threat-model-lite"}],"unlisted":false}}')}}]);