"use strict";(self.webpackChunknnlp_website=self.webpackChunknnlp_website||[]).push([[4222],{45317(e){e.exports=JSON.parse('{"tag":{"label":"evaluation","permalink":"/NNLP/docs/tags/evaluation","allTagsPath":"/NNLP/docs/tags","count":4,"items":[{"id":"08-evaluation/00-eval-overview","title":"Evaluation Overview","description":"AI is probabilistic. Your standards must be deterministic. Evaluation is the process of measuring the gap between the two.","permalink":"/NNLP/docs/08-evaluation/00-eval-overview"},{"id":"08-evaluation/01-quality-rubric","title":"Quality Rubric","description":"This rubric converts \\"it looks good\\" into a measurable score. Use it to grade AI outputs objectively before acceptance.","permalink":"/NNLP/docs/08-evaluation/01-quality-rubric"},{"id":"08-evaluation/05-scenario-scorecards","title":"Scenario Scorecards","description":"A Scenario Scorecard evaluates the entire lifecycle of an AI-assisted task. It answers: \\"Did the NNLP process actually work, or did we just generate code fast?\\"","permalink":"/NNLP/docs/08-evaluation/05-scenario-scorecards"},{"id":"09-templates/scenario-scorecard-template","title":"Template: Scenario Scorecard","description":"Use this scorecard to grade an end-to-end AI session. Be honest. If you skipped a step, mark it as skipped.","permalink":"/NNLP/docs/09-templates/scenario-scorecard-template"}],"unlisted":false}}')}}]);