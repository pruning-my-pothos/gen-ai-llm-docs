"use strict";(self.webpackChunknnlp_website=self.webpackChunknnlp_website||[]).push([[996],{74111(e){e.exports=JSON.parse('{"tag":{"label":"local-llm","permalink":"/NNLP/docs/tags/local-llm","allTagsPath":"/NNLP/docs/tags","count":1,"items":[{"id":"06-frameworks-and-tooling/03-local-inference","title":"Local Inference: Ollama","description":"When working with Red Zone data (PII, secrets, core IP), you cannot send code to the cloud. Local inference allows you to execute NNLP safely on your own hardware.","permalink":"/NNLP/docs/06-frameworks-and-tooling/03-local-inference"}],"unlisted":false}}')}}]);