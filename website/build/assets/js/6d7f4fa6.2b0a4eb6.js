"use strict";(self.webpackChunknnlp_website=self.webpackChunknnlp_website||[]).push([[1241],{30091(e){e.exports=JSON.parse('{"tag":{"label":"tooling","permalink":"/NNLP/docs/tags/tooling","allTagsPath":"/NNLP/docs/tags","count":4,"items":[{"id":"06-frameworks-and-tooling/02-cli-agents","title":"CLI Agents: Aider & Claude Code","description":"IDE tools are \\"Co-Pilots\\" (they help you type). CLI Agents are \\"Engineers\\" (they do the work while you supervise). They are best for large refactors, migrations, or test generation.","permalink":"/NNLP/docs/06-frameworks-and-tooling/02-cli-agents"},{"id":"06-frameworks-and-tooling/00-tooling-index","title":"Frameworks and Tooling","description":"The tool is not the method. A carpenter can use a hand saw or a power saw, but the geometry of the cut remains the same. NNLP works with any tool that allows context injection.","permalink":"/NNLP/docs/06-frameworks-and-tooling/00-tooling-index"},{"id":"06-frameworks-and-tooling/01-ide-setup-cursor","title":"IDE Setup: Cursor","description":"Cursor is currently the preferred IDE for NNLP because it treats Context Injection as a first-class feature. You can explicitly reference your specs using @Symbols, making the NNLP Loop frictionless.","permalink":"/NNLP/docs/06-frameworks-and-tooling/01-ide-setup-cursor"},{"id":"06-frameworks-and-tooling/03-local-inference","title":"Local Inference: Ollama","description":"When working with Red Zone data (PII, secrets, core IP), you cannot send code to the cloud. Local inference allows you to execute NNLP safely on your own hardware.","permalink":"/NNLP/docs/06-frameworks-and-tooling/03-local-inference"}],"unlisted":false}}')}}]);